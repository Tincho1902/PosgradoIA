{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imblearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imblearn\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix,roc_auc_score, classification_report, precision_recall_curve, auc, mean_absolute_error ,mean_squared_error, median_absolute_error \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos y exploramos el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataSet_Fraud.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Column Name |   Description\n",
    "\n",
    "step\t|   represents a unit of time where 1 step equals 1 hour.\n",
    "\n",
    "type\t|   type of online transaction.\n",
    "\n",
    "amount\t|   the amount of the transaction.\n",
    "\n",
    "nameOrig\t|   customer starting the transaction.\n",
    "\n",
    "oldbalanceOrg\t |   balance before the transaction.\n",
    "\n",
    "newbalanceOrig\t|   balance after the transaction.\n",
    "\n",
    "nameDest\t|   recipient of the transaction.\n",
    "\n",
    "oldbalanceDest\t|   initial balance of recipient before the transaction.\n",
    "\n",
    "newbalanceDest\t |   the new balance of recipient after the transaction.\n",
    "\n",
    "isFraud\t|   fraud transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts(['isFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimimos la forma del dataset\n",
    "    \n",
    "print(\"Nro. de Filas y columnas \", df.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chequeo de dtypes de todas las columnas\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscamos valores nulos \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropeamos la columna Id que no nos interesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudes = df[df['isFraud']==1]\n",
    "fraudes.describe().round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('De los fraudes se detectaron: \\n\\n',fraudes['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizamos y modificamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.get_dummies(data=df, columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que en muy pocos casos los destinatarios se repiten 2 veces y nunca se da una 3ra vez. Es información con alta cardinalidad y no aporta gran valor, salvo se quiera armar un registro de cuentas fraudulentas que en ese caso si aplican los nombres de cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_drop = df_dummy.drop(columns=['nameOrig','nameDest', 'isFlaggedFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,1,figsize=(18,8))\n",
    "sns.heatmap(df_dummy_drop.corr(), \n",
    "            annot=True,\n",
    "            ax=axes, \n",
    "            cmap='icefire',\n",
    "            vmin=-1,\n",
    "            vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_drop.corr()['isFraud'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas variables es muy dificil predecir si es fraude ya que no tienen correlacion con la variable de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_drop['emptied'] = np.where(df_dummy_drop['newbalanceOrig']==0, 1, 0)\n",
    "df_dummy_drop['origDiff'] = df_dummy_drop['oldbalanceOrg'] - df_dummy_drop['newbalanceOrig']\n",
    "df_dummy_drop['destDiff'] =  df_dummy_drop['newbalanceDest'] - df_dummy_drop['oldbalanceDest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_drop.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = df_dummy_drop[df_dummy_drop.isFraud==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.reindex(columns=['step',\n",
    "            'amount',\n",
    "            'emptied',\n",
    "            'origDiff',\n",
    "            'destDiff',\n",
    "            'oldbalanceOrg',\n",
    "            'newbalanceOrig',\n",
    "            'oldbalanceDest',\n",
    "            'newbalanceDest',\n",
    "            'isFraud',\n",
    "            'type_CASH_IN',\n",
    "            'type_CASH_OUT',\n",
    "            'type_DEBIT',\n",
    "            'type_PAYMENT',\n",
    "            'type_TRANSFER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['step',\n",
    "        'amount',\n",
    "        'emptied',\n",
    "        'origDiff',\n",
    "        'destDiff',\n",
    "        #'oldbalanceOrg',\n",
    "        #'newbalanceOrig',\n",
    "        #'oldbalanceDest',\n",
    "        #'newbalanceDest',\n",
    "        #'isFraud',\n",
    "        #'type_CASH_IN',\n",
    "        #'type_CASH_OUT',\n",
    "        #'type_DEBIT',\n",
    "        #'type_PAYMENT',\n",
    "        #'type_TRANSFER'\n",
    "]\n",
    "for column in columns:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20,4))\n",
    "    sns.boxplot(data=DF, x=column, ax=ax[0])\n",
    "    ax[0].set_title(f'{column.title()} Boxplot')\n",
    "    sns.histplot(data=DF, x=column, ax=ax[1], kde=True)\n",
    "    ax[1].set_title(f'{column.title()} Histogram')\n",
    "    fig.suptitle(f'{column.title()} Distribution'.replace('_', ' '), fontsize=15, color='brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[(DF.amount==DF.origDiff)==False].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(DF.emptied==1).value_counts().plot.pie(autopct='%1.1f%%')\n",
    "(DF.amount==DF.origDiff).value_counts().plot.pie(autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizo los casos fraudulentos:\n",
    "\n",
    "*   Estan distribuidos de forma uniforme a lo largo del mes (30 dias = 743h o steps)\n",
    "*   En el 98.1% de los casos la cuenta origen es vaciada\n",
    "*   Menos del 1% de las veces el monto de la transacción y el saldo descontado no coinciden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isFraud==1).value_counts().plot.pie(autopct='%1.3f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se está trabajando con una variable de salida muy desbalanceada, por lo tanto se buscará balancear las clases para entrenar el modelo y detectar con mayor presición la clase fraude = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_drop = df_dummy_drop.drop(columns=[#'step',\n",
    "                                            #'amount',\n",
    "                                            #'emptied',\n",
    "                                            #'origDiff',\n",
    "                                            #'destDiff',\n",
    "                                            'oldbalanceOrg',\n",
    "                                            'newbalanceOrig',\n",
    "                                            'oldbalanceDest',\n",
    "                                            'newbalanceDest',\n",
    "                                            #'isFraud',\n",
    "                                            #'type_CASH_IN',\n",
    "                                            #'type_CASH_OUT',\n",
    "                                            #'type_DEBIT',\n",
    "                                            #'type_PAYMENT',\n",
    "                                            #'type_TRANSFER'\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_dummy_drop.drop(columns='isFraud')\n",
    "y = df_dummy_drop.isFraud\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size = 0.10,random_state = 1000, stratify=y)\n",
    "print(f'Train data shape : {x_train.shape}') \n",
    "print(f'Distribución de la variable salida : \\n{y_train.value_counts(normalize=True)}')\n",
    "print(f'Test data shape : {x_test.shape}') \n",
    "print(f'Distribución de la variable salida : \\n{y_test.value_counts(normalize=True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos los datos eliminando la mediana y escalamos de acuerdo con metodo utilizado:\n",
    "*   MaxAbsScaler\n",
    "*   MinMaxScaler\n",
    "*   RobustScaler - Utilizamos este escalador por no estar influenciado por valores atípicos\n",
    "*   StandardScaler\n",
    "\n",
    "Para mas info ver: Comparar el efecto de diferentes escaladores en los datos con valores atípicos\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#maxabsscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "x_train = rs.fit_transform(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X Train : \", x_train.shape)\n",
    "print(\"X Test  : \", x_test.shape)\n",
    "print(\"Y Train : \", y_train.shape)\n",
    "print(\"Y Test  : \", y_test.shape)\n",
    "print('\\nY las etiquetas se distribuyen entre train y test de la siguiente forma:\\n')\n",
    "print('Train: \\n',y_train.value_counts(normalize=True),'\\n Test: \\n' , y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "print(dt.score(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cbb360768bf90aa5a59e865b3d88445392ae93b20a05da862e5531f6801afb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
